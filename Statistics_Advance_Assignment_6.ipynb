{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e06b2ea-3c6d-4948-8f26-ea8f92fbb5ce",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300bb73-7397-476a-aba7-fdcca6630c3c",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical method used to compare means of three or more groups to determine if there are significant differences among them. The validity of ANOVA results relies on several key assumptions:\n",
    "\n",
    "### Assumptions of ANOVA\n",
    "\n",
    "1. **Independence of Observations**: The observations within each group must be independent of each other. This means that the data points in one group should not influence the data points in another group.\n",
    "   \n",
    "2. **Normality**: The data within each group should be approximately normally distributed. This is especially important when sample sizes are small because ANOVA is robust to deviations from normality when sample sizes are large.\n",
    "\n",
    "3. **Homogeneity of Variances (Homoscedasticity)**: The variances among the groups should be approximately equal. This assumption ensures that each group contributes equally to the analysis.\n",
    "\n",
    "### Examples of Violations\n",
    "\n",
    "1. **Independence of Observations**:\n",
    "   - **Violation**: In a study where students are tested, if students discuss answers among themselves or if measurements are repeated on the same subjects without accounting for this repetition, the observations are not independent.\n",
    "   - **Impact**: Violating this assumption can lead to misleading conclusions because the dependencies among data points inflate the apparent sample size, thus impacting the statistical power and error rates.\n",
    "\n",
    "2. **Normality**:\n",
    "   - **Violation**: If the data within groups is heavily skewed or contains outliers, the normality assumption is violated.\n",
    "   - **Impact**: When normality is violated, especially with small sample sizes, the results of the ANOVA may be unreliable. This is because the F-test used in ANOVA is based on the assumption of normality, and significant deviations can affect the Type I error rate.\n",
    "\n",
    "3. **Homogeneity of Variances**:\n",
    "   - **Violation**: If one group's variance is significantly larger or smaller than the variances of other groups, the assumption of homogeneity of variances is violated.\n",
    "   - **Impact**: This violation affects the F-test's robustness, leading to an increased risk of Type I or Type II errors. In practice, it means that the test may indicate a significant difference when there is none, or fail to detect a difference that actually exists.\n",
    "\n",
    "### Addressing Violations\n",
    "\n",
    "- **Independence**: Ensure proper study design and data collection methods that maintain independence of observations.\n",
    "- **Normality**: Use transformations (e.g., log, square root) to normalize the data or use non-parametric alternatives like the Kruskal-Wallis test if normality cannot be achieved.\n",
    "- **Homogeneity of Variances**: Use tests like Levene's test to check for equal variances. If variances are unequal, consider using a Welch's ANOVA, which does not assume equal variances.\n",
    "\n",
    "By adhering to these assumptions and addressing potential violations, the validity of ANOVA results can be maintained, ensuring accurate and reliable conclusions from the data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f274fd5-6461-434b-a285-1d11d99e76fb",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc24fe-12f3-405d-8495-09ff4fd4c16a",
   "metadata": {},
   "source": [
    "The three main types of ANOVA are One-Way ANOVA, Two-Way ANOVA, and Repeated Measures ANOVA. Each type is used in different experimental designs and situations:\n",
    "\n",
    "### 1. One-Way ANOVA\n",
    "\n",
    "**Description**: One-Way ANOVA is used to compare the means of three or more independent (unrelated) groups to see if there is a statistically significant difference among them.\n",
    "\n",
    "**Situations**:\n",
    "- When you have one independent variable (factor) with multiple levels (groups) and you want to determine if there is a difference in the dependent variable across these groups.\n",
    "- Example: Comparing the test scores of students from different teaching methods (traditional, online, hybrid). Here, the independent variable is the teaching method, and the dependent variable is the test score.\n",
    "\n",
    "### 2. Two-Way ANOVA\n",
    "\n",
    "**Description**: Two-Way ANOVA is used to evaluate the effect of two independent variables on a dependent variable, and to understand if there is any interaction effect between the two independent variables.\n",
    "\n",
    "**Situations**:\n",
    "- When you have two independent variables and you want to investigate their individual effects on the dependent variable as well as any interaction effect between them.\n",
    "- Example: Studying the impact of different diets (high-protein, low-carb, balanced) and exercise regimens (none, moderate, intense) on weight loss. Here, the independent variables are diet and exercise regimen, and the dependent variable is weight loss.\n",
    "\n",
    "**Types of Two-Way ANOVA**:\n",
    "- **Without Interaction**: When the interaction effect between the two factors is not of interest.\n",
    "- **With Interaction**: When the interaction effect between the two factors is of interest, allowing you to see how the combination of different levels of factors affects the dependent variable.\n",
    "\n",
    "### 3. Repeated Measures ANOVA\n",
    "\n",
    "**Description**: Repeated Measures ANOVA is used when the same subjects are measured multiple times under different conditions or over time. It accounts for the correlation between the repeated measures on the same subjects.\n",
    "\n",
    "**Situations**:\n",
    "- When you have one group of subjects that undergoes multiple treatments or measurements, and you want to analyze the differences across these repeated measurements.\n",
    "- Example: Measuring the blood pressure of patients before, during, and after administering a medication. Here, the same patients are measured at different time points, and the dependent variable is blood pressure.\n",
    "\n",
    "**Advantages**:\n",
    "- Controls for individual variability, making the analysis more powerful.\n",
    "- Requires fewer subjects compared to a between-subjects design (e.g., One-Way ANOVA).\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **One-Way ANOVA**: Used for comparing the means of three or more independent groups for one independent variable.\n",
    "- **Two-Way ANOVA**: Used for examining the effects of two independent variables and their interaction on a dependent variable.\n",
    "- **Repeated Measures ANOVA**: Used for analyzing data where the same subjects are measured multiple times under different conditions or over time.\n",
    "\n",
    "Each type of ANOVA helps in understanding different aspects of the data and is chosen based on the design of the experiment and the research questions being addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae0ca6-afc3-4a86-8f97-4738849c0545",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f494b3-0b8a-40e4-a6eb-1163dc078e18",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA (Analysis of Variance) is a critical concept that involves dividing the total variability observed in the data into components attributable to different sources. Understanding this concept is essential because it allows researchers to determine the contribution of different factors to the overall variability and to test hypotheses about these factors. Hereâ€™s a detailed explanation:\n",
    "\n",
    "### Partitioning of Variance\n",
    "\n",
    "In ANOVA, the total variance observed in the data is partitioned into two main components:\n",
    "\n",
    "1. **Between-Group Variance (SSB)**: This component measures the variability due to the differences between the group means. It reflects how much the group means deviate from the overall mean of the data.\n",
    "   \n",
    "2. **Within-Group Variance (SSW)**: This component measures the variability within each group. It reflects how much the individual observations within each group deviate from their respective group means.\n",
    "\n",
    "### Mathematical Representation\n",
    "\n",
    "- **Total Sum of Squares (SST)**: This represents the total variability in the data.\n",
    "  \\[\n",
    "  SST = \\sum_{i=1}^{N} (X_i - \\bar{X})^2\n",
    "  \\]\n",
    "  where \\( X_i \\) is each individual observation, and \\( \\bar{X} \\) is the overall mean of all observations.\n",
    "\n",
    "- **Sum of Squares Between Groups (SSB)**: This represents the variability due to differences between group means.\n",
    "  \\[\n",
    "  SSB = \\sum_{j=1}^{k} n_j (\\bar{X}_j - \\bar{X})^2\n",
    "  \\]\n",
    "  where \\( n_j \\) is the number of observations in group \\( j \\), \\( \\bar{X}_j \\) is the mean of group \\( j \\), and \\( k \\) is the number of groups.\n",
    "\n",
    "- **Sum of Squares Within Groups (SSW)**: This represents the variability within each group.\n",
    "  \\[\n",
    "  SSW = \\sum_{j=1}^{k} \\sum_{i=1}^{n_j} (X_{ij} - \\bar{X}_j)^2\n",
    "  \\]\n",
    "  where \\( X_{ij} \\) is the \\( i \\)-th observation in group \\( j \\).\n",
    "\n",
    "### Why Partitioning of Variance is Important\n",
    "\n",
    "1. **Hypothesis Testing**: The partitioning of variance forms the basis for the F-test in ANOVA. By comparing the between-group variance to the within-group variance, we can test the null hypothesis that all group means are equal. The F-ratio is calculated as:\n",
    "   \\[\n",
    "   F = \\frac{\\text{MSB}}{\\text{MSW}}\n",
    "   \\]\n",
    "   where \\( \\text{MSB} \\) (Mean Square Between) is \\( \\frac{SSB}{k-1} \\) and \\( \\text{MSW} \\) (Mean Square Within) is \\( \\frac{SSW}{N-k} \\). A significant F-ratio indicates that the group means are not all equal.\n",
    "\n",
    "2. **Understanding Variability**: Partitioning helps in understanding the sources of variability in the data. It distinguishes between variability that is due to the treatment or grouping factor (between-group) and variability due to random error or individual differences (within-group).\n",
    "\n",
    "3. **Effect Size**: Partitioning of variance is also used to calculate effect sizes (e.g., Eta-squared \\(\\eta^2\\)), which provide a measure of the proportion of total variability that is attributable to the factor of interest.\n",
    "   \\[\n",
    "   \\eta^2 = \\frac{SSB}{SST}\n",
    "   \\]\n",
    "\n",
    "4. **Model Diagnostics**: By analyzing the partitioned variances, researchers can diagnose potential issues with the model, such as unequal variances (heteroscedasticity) or outliers, which might affect the validity of the ANOVA results.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Understanding the partitioning of variance in ANOVA is crucial for interpreting the results correctly and for conducting robust statistical analyses. It provides insights into the contribution of different factors to the overall variability in the data and forms the foundation for hypothesis testing and effect size estimation in ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32715aa5-82fc-4170-b431-3058e605a77a",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0363681a-f3ad-4b4b-a932-6b134c46d883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 60.0\n",
      "Explained Sum of Squares (SSE): 54.0\n",
      "Residual Sum of Squares (SSR): 6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Value': [4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = df['Value'].mean()\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = df.groupby('Group')['Value'].mean()\n",
    "\n",
    "# Calculate SST (Total Sum of Squares)\n",
    "df['Total_SS'] = (df['Value'] - overall_mean) ** 2\n",
    "SST = df['Total_SS'].sum()\n",
    "\n",
    "# Calculate SSE (Explained Sum of Squares)\n",
    "df['Explained_SS'] = df['Group'].map(group_means)\n",
    "df['Explained_SS'] = (df['Explained_SS'] - overall_mean) ** 2\n",
    "SSE = df['Explained_SS'].sum()\n",
    "\n",
    "# Calculate SSR (Residual Sum of Squares)\n",
    "df['Residual_SS'] = (df['Value'] - df['Group'].map(group_means)) ** 2\n",
    "SSR = df['Residual_SS'].sum()\n",
    "\n",
    "# Output the results\n",
    "print(f'Total Sum of Squares (SST): {SST}')\n",
    "print(f'Explained Sum of Squares (SSE): {SSE}')\n",
    "print(f'Residual Sum of Squares (SSR): {SSR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a92c767-2db1-4673-b93a-396d0a1a301e",
   "metadata": {},
   "source": [
    "Explanation of the Code\n",
    "Data Preparation:\n",
    "\n",
    "A sample dataset is created with two columns: Group and Value.\n",
    "The data is loaded into a pandas DataFrame.\n",
    "Calculate the Overall Mean:\n",
    "\n",
    "The overall mean of the Value column is calculated.\n",
    "Calculate Group Means:\n",
    "\n",
    "The mean of the Value column is calculated for each group.\n",
    "Calculate Total Sum of Squares (SST):\n",
    "\n",
    "For each observation, the squared difference between the observation and the overall mean is computed.\n",
    "SST is the sum of these squared differences.\n",
    "Calculate Explained Sum of Squares (SSE):\n",
    "\n",
    "For each observation, the mean value of its group is computed and the squared difference between the group mean and the overall mean is calculated.\n",
    "SSE is the sum of these squared differences.\n",
    "Calculate Residual Sum of Squares (SSR):\n",
    "\n",
    "For each observation, the squared difference between the observation and its group mean is computed.\n",
    "SSR is the sum of these squared differences.\n",
    "Output\n",
    "The code outputs the values of SST, SSE, and SSR, which are essential for understanding the variation in the data attributed to different sources.\n",
    "\n",
    "By following this process, you can perform these calculations manually, providing a deeper understanding of the components of variance in ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b8e19-b6c2-4c45-b8d4-e1f328497d97",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e60b87-d9b0-41f1-aac2-6e7b75dddd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (0.13.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (22.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90b53f8-8fd6-449d-9bb8-2867cb10c2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          sum_sq   df         F    PR(>F)\n",
      "C(FactorA)             26.206520  2.0  7.577789  0.024952\n",
      "C(FactorB)              0.133333  2.0  0.038554  0.849231\n",
      "C(FactorA):C(FactorB)  17.200000  4.0  2.486747  0.134738\n",
      "Residual               13.833333  8.0       NaN       NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 3\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'FactorA': ['A1', 'A1', 'A1', 'A2', 'A2', 'A2', 'A3', 'A3', 'A3', 'A1', 'A1', 'A2', 'A2', 'A3', 'A3'],\n",
    "    'FactorB': ['B1', 'B1', 'B2', 'B2', 'B2', 'B3', 'B3', 'B3', 'B1', 'B1', 'B2', 'B2', 'B1', 'B1', 'B3'],\n",
    "    'Value': [5, 6, 7, 8, 8, 9, 10, 10, 5, 6, 7, 8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Value ~ C(FactorA) + C(FactorB) + C(FactorA):C(FactorB)', data=df).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf58d2bd-859f-40e2-b0ba-96d280c59af3",
   "metadata": {},
   "source": [
    "Explanation\n",
    "Data Preparation:\n",
    "\n",
    "A sample dataset is created with two factors FactorA and FactorB, and a dependent variable Value.\n",
    "The data is loaded into a pandas DataFrame.\n",
    "Fitting the ANOVA Model:\n",
    "\n",
    "The ols function from statsmodels.formula.api is used to specify the model formula. Here, Value ~ C(FactorA) + C(FactorB) + C(FactorA):C(FactorB) specifies that the dependent variable Value is modeled as a function of FactorA, FactorB, and their interaction.\n",
    "C(FactorA) and C(FactorB) indicate that these variables are categorical.\n",
    "Performing the ANOVA:\n",
    "\n",
    "The sm.stats.anova_lm function performs the ANOVA on the fitted model.\n",
    "typ=2 specifies the type of sum of squares to be used (Type II is common in ANOVA).\n",
    "Displaying the Results:\n",
    "\n",
    "The ANOVA table is printed, showing the sum of squares, degrees of freedom, F-statistics, and p-values for the main effects and interaction effects.\n",
    "Interpreting the Results\n",
    "The output ANOVA table includes:\n",
    "\n",
    "Sum of Squares (SS): Measures the variability explained by each factor.\n",
    "Degrees of Freedom (df): Number of levels in the factor minus one.\n",
    "F-Statistic: Ratio of the mean square of the factor to the mean square of the error.\n",
    "p-Value: Significance level of the factor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70ac1a-06cd-4078-9439-fe7b3bc1d908",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec577185-7780-4632-88cf-0519d301bfb9",
   "metadata": {},
   "source": [
    "Interpretation of One-Way ANOVA Results\n",
    "When you conduct a one-way ANOVA and obtain an F-statistic of 5.23 and a p-value of 0.02, the results provide insights into whether there are statistically significant differences between the means of the groups you are comparing.\n",
    "\n",
    "Understanding the Results\n",
    "F-Statistic (5.23):\n",
    "\n",
    "The F-statistic is a ratio of the variance between the group means to the variance within the groups.\n",
    "An F-statistic of 5.23 indicates that the variability between the group means is 5.23 times the variability within the groups.\n",
    "A higher F-statistic suggests that there is more variability between the groups relative to within the groups, which may indicate significant differences among the group means.\n",
    "p-Value (0.02):\n",
    "\n",
    "The p-value is the probability of obtaining an F-statistic at least as extreme as the one observed, assuming that the null hypothesis is true.\n",
    "A p-value of 0.02 means there is a 2% chance of observing such an F-statistic if the null hypothesis (that all group means are equal) is true.\n",
    "Typically, a p-value less than 0.05 is considered statistically significant.\n",
    "Conclusion\n",
    "Given the F-statistic of 5.23 and the p-value of 0.02, you can draw the following conclusions:\n",
    "\n",
    "Statistical Significance: Since the p-value (0.02) is less than the common alpha level of 0.05, you reject the null hypothesis. This means you have sufficient evidence to conclude that there are statistically significant differences between the group means.\n",
    "\n",
    "Implications: The significant result suggests that at least one group mean is different from the others. However, the ANOVA does not tell you which specific groups are different from each other or the nature of these differences.\n",
    "\n",
    "Next Steps\n",
    "To determine which groups are significantly different from each other, you should conduct post hoc tests (multiple comparisons tests), such as Tukey's HSD (Honestly Significant Difference), Bonferroni, or ScheffÃ© tests. These tests help to identify the specific pairs of groups that have significant differences in their means.\n",
    "\n",
    "Example of Post Hoc Testing in Python\n",
    "Hereâ€™s how you might proceed with Tukeyâ€™s HSD test using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590f6459-0cf3-48cf-aa09-5c4e9935d44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sum_sq   df     F  PR(>F)\n",
      "C(Group)    54.0  2.0  27.0   0.001\n",
      "Residual     6.0  6.0   NaN     NaN\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------\n",
      "     A      B      3.0 0.0242 0.4948 5.5052   True\n",
      "     A      C      6.0 0.0008 3.4948 8.5052   True\n",
      "     B      C      3.0 0.0242 0.4948 5.5052   True\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Value': [4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('Value ~ C(Group)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# Perform Tukey's HSD post hoc test\n",
    "tukey = pairwise_tukeyhsd(endog=df['Value'], groups=df['Group'], alpha=0.05)\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f583fc3d-fa0a-493f-87e6-9f6e8cbb3f44",
   "metadata": {},
   "source": [
    "Interpretation of Post Hoc Results\n",
    "The post hoc test results will show you which specific group means differ from each other and provide confidence intervals for the differences. This detailed comparison helps you understand the exact nature of the differences among the groups.\n",
    "\n",
    "Summary\n",
    "The F-statistic of 5.23 and a p-value of 0.02 indicate statistically significant differences between the group means.\n",
    "To identify which groups are different, conduct post hoc tests.\n",
    "These steps provide a complete understanding of where and how the group means differ, beyond the initial ANOVA results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53df03-fe1d-4b64-bc74-6770fd19abe7",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fbb541-7730-4951-9d52-656155228541",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA requires careful consideration to ensure the validity and reliability of the results. Here are some common methods for handling missing data and their potential consequences:\n",
    "\n",
    "1. Listwise Deletion (Complete Case Analysis)\n",
    "Description: Exclude any subject with missing data for any time point or condition from the analysis.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Simple to implement.\n",
    "Maintains the structure of the data without making assumptions about the missing data.\n",
    "Disadvantages:\n",
    "\n",
    "Reduces the sample size, which can decrease statistical power.\n",
    "Can lead to biased results if the data are not missing completely at random (MCAR).\n",
    "2. Pairwise Deletion\n",
    "Description: Use all available data points for each analysis, excluding only the specific missing data points.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Utilizes more data compared to listwise deletion.\n",
    "Maintains a larger sample size.\n",
    "Disadvantages:\n",
    "\n",
    "Can lead to inconsistent results since different analyses may be based on different subsets of data.\n",
    "May violate the assumptions of repeated measures ANOVA, as the data structure can become unbalanced.\n",
    "3. Mean Imputation\n",
    "Description: Replace missing values with the mean of the available data for that variable.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Simple to implement.\n",
    "Preserves sample size.\n",
    "Disadvantages:\n",
    "\n",
    "Underestimates the variability in the data.\n",
    "Can lead to biased estimates and artificially narrow confidence intervals.\n",
    "Ignores the uncertainty associated with the missing data.\n",
    "4. Last Observation Carried Forward (LOCF)\n",
    "Description: Replace missing values with the last observed value for that subject.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Simple and intuitive.\n",
    "Preserves the within-subject correlation structure.\n",
    "Disadvantages:\n",
    "\n",
    "Can introduce bias if the missing data pattern is not random.\n",
    "Assumes that the last observed value is a good estimate for the missing value, which may not be the case.\n",
    "5. Linear Interpolation\n",
    "Description: Replace missing values with a value interpolated linearly between the previous and next observed values.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Simple to implement.\n",
    "Maintains some of the within-subject trend.\n",
    "Disadvantages:\n",
    "\n",
    "Assumes linearity between observed values, which may not be accurate.\n",
    "Can still underestimate variability.\n",
    "6. Multiple Imputation\n",
    "Description: Replace each missing value with a set of plausible values drawn from a distribution, analyze each complete dataset, and then combine the results.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Accounts for the uncertainty associated with the missing data.\n",
    "Provides valid statistical inferences if the imputation model is correct.\n",
    "Preserves sample size and variability.\n",
    "Disadvantages:\n",
    "\n",
    "More complex to implement and computationally intensive.\n",
    "Requires careful specification of the imputation model.\n",
    "Results can be sensitive to the model assumptions.\n",
    "7. Mixed-Effects Models\n",
    "Description: Use mixed-effects models that can handle unbalanced data and missing values more flexibly.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Can provide unbiased estimates if data are missing at random (MAR).\n",
    "Can handle unbalanced data structures naturally.\n",
    "Models within-subject correlation.\n",
    "Disadvantages:\n",
    "\n",
    "More complex to implement and interpret.\n",
    "Requires appropriate specification of the random effects structure.\n",
    "Example of Handling Missing Data in Python\n",
    "Hereâ€™s how you might handle missing data using multiple imputation with the statsmodels library in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e5aede-1dc3-46c8-83d5-d9083da1002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Mixed Linear Model Regression Results\n",
      "======================================================\n",
      "Model:            MixedLM Dependent Variable: Score   \n",
      "No. Observations: 9       Method:             REML    \n",
      "No. Groups:       3       Scale:              1.1667  \n",
      "Min. group size:  3       Log-Likelihood:     -13.9864\n",
      "Max. group size:  3       Converged:          Yes     \n",
      "Mean group size:  3.0                                 \n",
      "------------------------------------------------------\n",
      "            Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "------------------------------------------------------\n",
      "Intercept    8.333    1.171  7.119 0.000  6.039 10.628\n",
      "Time        -0.500    0.441 -1.134 0.257 -1.364  0.364\n",
      "Subject Var  1.389    1.947                           \n",
      "======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.imputation.mice import MICEData\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "\n",
    "# Sample data with missing values\n",
    "data = {\n",
    "    'Subject': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "    'Time': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "    'Score': [np.nan, 6, 5, 7, np.nan, 8, 9, 10, np.nan]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Multiple Imputation\n",
    "mice_data = MICEData(df)\n",
    "imputed_data = mice_data.data\n",
    "\n",
    "# Mixed-Effects Model\n",
    "model = MixedLM.from_formula('Score ~ Time', groups='Subject', data=imputed_data)\n",
    "result = model.fit()\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ea735-bebc-455a-9dce-375b14b432a2",
   "metadata": {},
   "source": [
    "Consequences of Different Methods\n",
    "Bias: Some methods, like mean imputation and LOCF, can introduce bias, especially if data are not missing completely at random (MCAR).\n",
    "Variability: Methods like mean imputation can underestimate variability, leading to narrower confidence intervals.\n",
    "Statistical Power: Listwise deletion reduces sample size, which can decrease statistical power.\n",
    "Complexity: Methods like multiple imputation and mixed-effects models are more complex but provide more accurate and valid results if assumptions are met.\n",
    "In summary, the choice of method for handling missing data in a repeated measures ANOVA depends on the missing data mechanism, the proportion of missing data, and the balance between simplicity and accuracy. Mixed-effects models and multiple imputation are generally preferred for their robustness and ability to handle missing data more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d397a2-498c-4e61-aa07-f655bc5801fe",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e88827-3d0c-4ad1-a8ed-c71d204b3623",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after ANOVA when you find a statistically significant effect and need to determine which specific group means are different from each other. These tests control for the increased risk of Type I errors (false positives) that arise from making multiple comparisons. Here are some common post-hoc tests and their uses:\n",
    "\n",
    "Common Post-Hoc Tests\n",
    "Tukey's Honestly Significant Difference (HSD) Test\n",
    "\n",
    "Use: When you want to compare all possible pairs of group means while controlling for Type I error.\n",
    "Example: After finding a significant effect in a one-way ANOVA comparing the mean test scores of students from four different teaching methods, you use Tukeyâ€™s HSD to determine which specific teaching methods differ in effectiveness.\n",
    "Bonferroni Correction\n",
    "\n",
    "Use: When making multiple comparisons, you divide the significance level (alpha) by the number of comparisons to control for Type I error.\n",
    "Example: In a clinical trial comparing the efficacy of five different drugs, you use the Bonferroni correction to adjust the significance level for the 10 pairwise comparisons.\n",
    "ScheffÃ©'s Test\n",
    "\n",
    "Use: When you need a more conservative test that can be used for any type of comparison, not just pairwise comparisons.\n",
    "Example: In an educational study examining the performance of students in various disciplines (e.g., math, science, literature), ScheffÃ©â€™s test can be used to compare combinations of group means, not just individual pairs.\n",
    "Dunnett's Test\n",
    "\n",
    "Use: When you want to compare each treatment group mean to a single control group mean.\n",
    "Example: In a pharmaceutical study, you compare the mean blood pressure reduction of three new drugs to a placebo group using Dunnettâ€™s test.\n",
    "Fisher's Least Significant Difference (LSD) Test\n",
    "\n",
    "Use: When you want a more liberal test that does not adjust for multiple comparisons, used typically when you have a small number of groups.\n",
    "Example: In an agricultural study comparing the yield of crops treated with three different fertilizers, Fisherâ€™s LSD can be used to compare each pair of fertilizers.\n",
    "Holmâ€™s Sequential Bonferroni Procedure\n",
    "\n",
    "Use: When you want a stepwise procedure that is less conservative than the Bonferroni correction.\n",
    "Example: In a psychology study investigating the effects of various therapies on anxiety levels, Holmâ€™s procedure adjusts the p-values in a stepwise manner for multiple comparisons.\n",
    "Example Situation Requiring Post-Hoc Tests\n",
    "Situation: A researcher conducts a one-way ANOVA to examine the effect of four different diets on weight loss. The ANOVA results show a significant difference among the group means.\n",
    "\n",
    "Post-Hoc Test: The researcher decides to use Tukeyâ€™s HSD test to determine which specific diets differ in their effectiveness. The test compares all possible pairs of diet groups and identifies the pairs with significant differences in mean weight loss.\n",
    "\n",
    "Python Example Using Tukey's HSD Test\n",
    "Hereâ€™s how you might perform Tukeyâ€™s HSD test using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ffec915-2ee8-4fe1-9d45-ee093b5850d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             sum_sq   df          F   PR(>F)\n",
      "C(Diet)   13.666667  3.0  10.933333  0.00334\n",
      "Residual   3.333333  8.0        NaN      NaN\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------\n",
      "     A      B   2.6667 0.0043  0.9789 4.3545   True\n",
      "     A      C   2.3333 0.0095  0.6455 4.0211   True\n",
      "     A      D      1.0  0.301 -0.6878 2.6878  False\n",
      "     B      C  -0.3333 0.9187 -2.0211 1.3545  False\n",
      "     B      D  -1.6667 0.0529 -3.3545 0.0211  False\n",
      "     C      D  -1.3333 0.1289 -3.0211 0.3545  False\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Diet': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'D', 'D', 'D'],\n",
    "    'WeightLoss': [5, 6, 5.5, 8, 7.5, 9, 7, 8.5, 8, 6, 6.5, 7]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('WeightLoss ~ C(Diet)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# Perform Tukey's HSD post hoc test\n",
    "tukey = pairwise_tukeyhsd(endog=df['WeightLoss'], groups=df['Diet'], alpha=0.05)\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b9d8a-28c1-45cf-9af1-90f0a1a7b8fb",
   "metadata": {},
   "source": [
    "Interpretation of Post-Hoc Results\n",
    "The output from Tukeyâ€™s HSD test will show:\n",
    "\n",
    "The mean difference between each pair of groups.\n",
    "Confidence intervals for these differences.\n",
    "p-values indicating whether the differences are statistically significant.\n",
    "This information helps you understand which specific diets differ in their effects on weight loss, providing more detailed insights beyond the overall significant effect found by the ANOVA.\n",
    "\n",
    "Summary\n",
    "Post-hoc tests are essential for determining specific group differences after finding a significant effect in ANOVA. The choice of post-hoc test depends on the nature of the comparisons and the need to control for Type I error. Using these tests appropriately ensures valid and reliable conclusions about group differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4528d7-3401-483c-be1c-065284650a59",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960656b4-4627-413c-ba93-a3dd8cd6070c",
   "metadata": {},
   "source": [
    "To conduct a one-way ANOVA in Python to compare the mean weight loss of three diets (A, B, and C) and determine if there are significant differences between the means, follow these steps:\n",
    "\n",
    "Prepare the Data:\n",
    "\n",
    "Collect the weight loss data from 50 participants, randomly assigned to one of the three diets.\n",
    "Conduct the One-Way ANOVA:\n",
    "\n",
    "Use the statsmodels library to perform the ANOVA.\n",
    "Report and Interpret the Results:\n",
    "\n",
    "Calculate the F-statistic and p-value.\n",
    "Interpret the statistical significance of the results.\n",
    "Here is an example code to perform the one-way ANOVA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0629ec2-f113-466c-a5df-3010c60237d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             sum_sq    df        F    PR(>F)\n",
      "C(Diet)    7.771108   2.0  4.15755  0.021751\n",
      "Residual  43.925158  47.0      NaN       NaN\n",
      "F-statistic: 4.157549709839448\n",
      "p-value: 0.02175067679044752\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data: 50 participants, randomly assigned to one of three diets (A, B, C)\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Diet': np.random.choice(['A', 'B', 'C'], size=50),\n",
    "    'WeightLoss': np.random.normal(loc=0, scale=1, size=50)  # Simulated weight loss data\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('WeightLoss ~ C(Diet)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Report the results\n",
    "print(anova_table)\n",
    "\n",
    "# F-statistic and p-value\n",
    "f_statistic = anova_table['F'][0]\n",
    "p_value = anova_table['PR(>F)'][0]\n",
    "\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce6d3b-4c75-453b-84e9-e125a0003e11",
   "metadata": {},
   "source": [
    "Explanation of the Code\n",
    "Data Preparation:\n",
    "\n",
    "Simulate data for 50 participants with random assignment to diets A, B, and C.\n",
    "Generate random weight loss values using a normal distribution for simplicity. Replace this with actual data if available.\n",
    "Fit the ANOVA Model:\n",
    "\n",
    "Use the ols function from statsmodels.formula.api to specify the model formula (WeightLoss ~ C(Diet)).\n",
    "Fit the model and perform ANOVA using sm.stats.anova_lm.\n",
    "Report the Results:\n",
    "\n",
    "Extract and print the F-statistic and p-value from the ANOVA table.\n",
    "Interpreting the Results\n",
    "Suppose the output is as follows (the exact numbers will vary due to random data):\n",
    "\n",
    "r\n",
    "Copy code\n",
    "                sum_sq   df         F    PR(>F)\n",
    "C(Diet)      4.545833  2.0  2.341424  0.105839\n",
    "Residual    45.637801  47.0       NaN       NaN\n",
    "F-statistic: 2.341424\n",
    "p-value: 0.105839\n",
    "F-statistic (2.341424):\n",
    "\n",
    "This value compares the variance between the group means to the variance within the groups.\n",
    "A higher F-statistic indicates a greater likelihood that there are significant differences between the group means.\n",
    "p-Value (0.105839):\n",
    "\n",
    "The p-value indicates the probability of observing such an F-statistic if the null hypothesis (that all group means are equal) is true.\n",
    "In this case, the p-value is 0.105839, which is greater than the common significance level of 0.05.\n",
    "Conclusion\n",
    "Since the p-value (0.105839) is greater than 0.05, we fail to reject the null hypothesis. This means there is not enough evidence to conclude that there are significant differences between the mean weight loss of the three diets.\n",
    "\n",
    "Summary\n",
    "The one-way ANOVA did not find statistically significant differences in mean weight loss between the three diets.\n",
    "If a lower p-value (less than 0.05) had been obtained, it would indicate significant differences, prompting the use of post-hoc tests to identify specific group differences.\n",
    "This example provides a comprehensive method to perform and interpret a one-way ANOVA using Python. For actual data, replace the simulated values with the real weight loss measurements from the study participants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83eecdd-1e3c-4594-81e7-be27075e320d",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143cff1f-9ff8-43da-b5c8-81bb2e37a85a",
   "metadata": {},
   "source": [
    "To conduct a two-way ANOVA in Python to determine if there are any main effects or interaction effects between software programs (Program A, Program B, and Program C) and employee experience level (novice vs. experienced) on the average time it takes to complete a task, follow these steps:\n",
    "\n",
    "Step-by-Step Guide\n",
    "Prepare the Data:\n",
    "\n",
    "Collect data on task completion time, software program, and experience level for 30 employees.\n",
    "Conduct the Two-Way ANOVA:\n",
    "\n",
    "Use the statsmodels library to perform the ANOVA.\n",
    "Report and Interpret the Results:\n",
    "\n",
    "Calculate and interpret the F-statistics and p-values for the main effects and interaction effects.\n",
    "Example Code\n",
    "Here is an example code to perform the two-way ANOVA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e234f9f-cda1-4ab0-9d32-44336e61a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(Program)                  25.883173   2.0  0.136986  0.872659\n",
      "C(Experience)               13.048491   1.0  0.138118  0.713420\n",
      "C(Program):C(Experience)    67.097761   2.0  0.355113  0.704716\n",
      "Residual                  2267.368865  24.0       NaN       NaN\n",
      "F-statistic for Program: 0.13698612455678702, p-value: 0.8726592315552775\n",
      "F-statistic for Experience: 0.13811770247946006, p-value: 0.7134204723690611\n",
      "F-statistic for Interaction: 0.3551134265795373, p-value: 0.7047159657689974\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data: 30 employees, randomly assigned to one of three programs and experience levels\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Program': np.random.choice(['A', 'B', 'C'], size=30),\n",
    "    'Experience': np.random.choice(['Novice', 'Experienced'], size=30),\n",
    "    'Time': np.random.normal(loc=50, scale=10, size=30)  # Simulated task completion times\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Report the results\n",
    "print(anova_table)\n",
    "\n",
    "# Extracting F-statistics and p-values\n",
    "f_program = anova_table['F'][0]\n",
    "p_program = anova_table['PR(>F)'][0]\n",
    "f_experience = anova_table['F'][1]\n",
    "p_experience = anova_table['PR(>F)'][1]\n",
    "f_interaction = anova_table['F'][2]\n",
    "p_interaction = anova_table['PR(>F)'][2]\n",
    "\n",
    "print(f\"F-statistic for Program: {f_program}, p-value: {p_program}\")\n",
    "print(f\"F-statistic for Experience: {f_experience}, p-value: {p_experience}\")\n",
    "print(f\"F-statistic for Interaction: {f_interaction}, p-value: {p_interaction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba8534-e7ea-43c1-857f-dcf94e926a09",
   "metadata": {},
   "source": [
    "Explanation of the Code\n",
    "Data Preparation:\n",
    "\n",
    "Simulate data for 30 employees with random assignment to three software programs and two experience levels.\n",
    "Generate random task completion times using a normal distribution for simplicity. Replace this with actual data if available.\n",
    "Fit the ANOVA Model:\n",
    "\n",
    "Use the ols function from statsmodels.formula.api to specify the model formula (Time ~ C(Program) + C(Experience) + C(Program):C(Experience)).\n",
    "Fit the model and perform ANOVA using sm.stats.anova_lm.\n",
    "Report the Results:\n",
    "\n",
    "Extract and print the F-statistics and p-values from the ANOVA table for the main effects and interaction effects.\n",
    "Interpreting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f95aa6-fc64-4923-9d96-3c8457929685",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "Main Effect of Program:\n",
    "\n",
    "F-statistic: 0.442983\n",
    "p-value: 0.647440\n",
    "Interpretation: Since the p-value (0.647440) is greater than 0.05, there is no significant main effect of the software program on task completion time.\n",
    "Main Effect of Experience:\n",
    "\n",
    "F-statistic: 1.054516\n",
    "p-value: 0.312622\n",
    "Interpretation: Since the p-value (0.312622) is greater than 0.05, there is no significant main effect of employee experience level on task completion time.\n",
    "Interaction Effect:\n",
    "\n",
    "F-statistic: 0.330444\n",
    "p-value: 0.721661\n",
    "Interpretation: Since the p-value (0.721661) is greater than 0.05, there is no significant interaction effect between the software program and employee experience level on task completion time.\n",
    "Summary\n",
    "The two-way ANOVA results indicate that there are no significant differences in the average time to complete the task based on the software program, employee experience level, or their interaction. This suggests that neither the choice of software program nor the experience level of the employees significantly affects the time it takes to complete the task.\n",
    "\n",
    "For more accurate analysis, use actual data and ensure the assumptions of ANOVA are met. If significant effects were found, post-hoc tests could be conducted to determine specific group differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe8079a-f7e8-41ed-aeaa-04d6f1b76697",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd243b2-11c0-46e3-820d-455e9665b7da",
   "metadata": {},
   "source": [
    "To conduct a two-sample t-test in Python to determine if there are any significant differences in test scores between the control group (traditional teaching method) and the experimental group (new teaching method), followed by a post-hoc test if the results are significant, follow these steps:\n",
    "\n",
    "Step-by-Step Guide\n",
    "Prepare the Data:\n",
    "\n",
    "Collect the test scores for the control and experimental groups (100 students in each group).\n",
    "Conduct the Two-Sample T-Test:\n",
    "\n",
    "Use the scipy.stats module to perform the two-sample t-test.\n",
    "Perform Post-Hoc Test (if necessary):\n",
    "\n",
    "If the results of the t-test are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "Example Code\n",
    "Here's an example code to perform the two-sample t-test and follow up with a post-hoc test if the results are significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5033598-499a-4e88-9ab9-f17230005181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "T-statistic: -4.754695943505281\n",
      "P-value: 3.819135262679478e-06\n",
      "Significant differences detected. Conducting post-hoc test...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate sample data for control and experimental groups (replace with actual data)\n",
    "np.random.seed(42)\n",
    "control_group = np.random.normal(loc=70, scale=10, size=100)  # Control group test scores\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=100)  # Experimental group test scores\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Report the results of the t-test\n",
    "print(f\"Two-Sample T-Test Results:\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# If the results are significant (p-value < 0.05), conduct a post-hoc test\n",
    "if p_value < 0.05:\n",
    "    # Example of post-hoc test (e.g., Tukey's HSD)\n",
    "    # Replace this with an appropriate post-hoc test based on your data and requirements\n",
    "    print(\"Significant differences detected. Conducting post-hoc test...\")\n",
    "    # Your post-hoc test code here\n",
    "else:\n",
    "    print(\"No significant differences detected. Post-hoc test not required.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03a378-788e-4eb0-bbd5-70c439fd06a0",
   "metadata": {},
   "source": [
    "Interpretation of Results\n",
    "Two-Sample T-Test Results:\n",
    "\n",
    "T-statistic: Measures the difference between the means of the two groups relative to the variation in the data.\n",
    "P-value: Indicates the probability of observing such a large t-statistic if the null hypothesis (that the means of the two groups are equal) is true.\n",
    "Significance Level (Î±):\n",
    "\n",
    "A common threshold for significance is Î± = 0.05. If the p-value is less than Î±, the results are considered statistically significant, indicating that there is evidence to reject the null hypothesis.\n",
    "Interpretation:\n",
    "\n",
    "If the p-value is less than 0.05, you conclude that there is a significant difference in test scores between the control and experimental groups.\n",
    "If the p-value is not significant, there is insufficient evidence to conclude that there is a significant difference in test scores between the two groups.\n",
    "Post-Hoc Test\n",
    "If the results of the t-test are significant, you can conduct a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "Common post-hoc tests include Tukey's HSD (Honestly Significant Difference), Bonferroni correction, or Dunnett's test, depending on your specific requirements and assumptions about the data.\n",
    "Summary\n",
    "The two-sample t-test is used to compare the means of two groups and determine if there is a significant difference between them.\n",
    "If the results are significant, follow up with a post-hoc test to identify specific group differences.\n",
    "Choose an appropriate post-hoc test based on your data and research objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3dae03-a149-47b0-932e-d395d9293d00",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589b980-c4df-42c1-82c4-cdcc418263e7",
   "metadata": {},
   "source": [
    "To conduct a repeated measures ANOVA in Python to determine if there are any significant differences in the average daily sales between three retail stores (Store A, Store B, and Store C), followed by a post-hoc test if the results are significant, follow these steps:\n",
    "\n",
    "Step-by-Step Guide\n",
    "Prepare the Data:\n",
    "\n",
    "Collect daily sales data for each store for the selected 30 days.\n",
    "Reshape the Data:\n",
    "\n",
    "Prepare the data in a format suitable for repeated measures analysis. This typically involves reshaping the data into a long format where each row represents one observation (sales on a particular day) and includes columns for the store identifier and the sales amount.\n",
    "Conduct the Repeated Measures ANOVA:\n",
    "\n",
    "Use the statsmodels library to perform the repeated measures ANOVA.\n",
    "Perform Post-Hoc Test (if necessary):\n",
    "\n",
    "If the results of the ANOVA are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other.\n",
    "Example Code\n",
    "Here's an example code to perform the repeated measures ANOVA and follow up with a post-hoc test if the results are significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31a6cdd-5b51-4d8b-a47d-ee3f325e16da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store  1.9260 2.0000 58.0000 0.1549\n",
      "===================================\n",
      "\n",
      "\n",
      "No significant differences detected. Post-hoc test not required.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data for Store A, Store B, and Store C (replace with actual data)\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Day': np.arange(1, 31),  # 30 days\n",
    "    'Store_A': np.random.randint(1000, 5000, size=30),  # Sales for Store A\n",
    "    'Store_B': np.random.randint(800, 4500, size=30),    # Sales for Store B\n",
    "    'Store_C': np.random.randint(1200, 5200, size=30)    # Sales for Store C\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Melt the DataFrame to long format suitable for repeated measures analysis\n",
    "df_long = pd.melt(df, id_vars='Day', var_name='Store', value_name='Sales')\n",
    "\n",
    "# Fit the repeated measures ANOVA model\n",
    "anova_model = AnovaRM(df_long, 'Sales', 'Day', within=['Store']).fit()\n",
    "\n",
    "# Report the results of the repeated measures ANOVA\n",
    "print(anova_model.summary())\n",
    "\n",
    "# If the results are significant (p-value < 0.05), conduct a post-hoc test\n",
    "if anova_model.anova_table['Pr > F'][0] < 0.05:\n",
    "    print(\"\\nSignificant differences detected. Conducting post-hoc test...\")\n",
    "    # Perform post-hoc test (e.g., Tukey's HSD)\n",
    "    posthoc = pairwise_tukeyhsd(df_long['Sales'], df_long['Store'])\n",
    "    print(posthoc)\n",
    "else:\n",
    "    print(\"\\nNo significant differences detected. Post-hoc test not required.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea0270-a5bd-42c5-8225-1662dd75fa23",
   "metadata": {},
   "source": [
    "Interpretation of Results\n",
    "Repeated Measures ANOVA Results:\n",
    "\n",
    "The output includes the F-statistic, degrees of freedom, and p-value for the main effect of Store.\n",
    "If the p-value is less than 0.05, you conclude that there is a significant difference in sales between the stores.\n",
    "Post-Hoc Test Results:\n",
    "\n",
    "If the results of the repeated measures ANOVA are significant, the post-hoc test (e.g., Tukey's HSD) identifies which store(s) differ significantly from each other.\n",
    "The output includes group means, confidence intervals, and p-values for pairwise comparisons between stores.\n",
    "Summary\n",
    "Repeated measures ANOVA is used to analyze data where multiple measurements are taken from the same subjects or objects over time or under different conditions.\n",
    "If the results of the ANOVA are significant, post-hoc tests can be conducted to identify specific group differences.\n",
    "Choose an appropriate post-hoc test based on your data and research objectives, such as Tukey's HSD for comparing multiple groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
